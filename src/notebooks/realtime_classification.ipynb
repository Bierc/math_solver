{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 17:17:46.788032: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-01 17:17:46.812159: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-01 17:17:46.851108: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-01 17:17:46.851158: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-01 17:17:46.871210: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-01 17:17:47.845566: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sympy as sp\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['+', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '=', 'times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 17:18:19.907036: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2024-07-01 17:18:19.907057: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:134] retrieving CUDA diagnostic information for host: pablo-sene\n",
      "2024-07-01 17:18:19.907060: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:141] hostname: pablo-sene\n",
      "2024-07-01 17:18:19.907176: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:165] libcuda reported version is: 535.183.1\n",
      "2024-07-01 17:18:19.907189: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:169] kernel reported version is: 535.183.1\n",
      "2024-07-01 17:18:19.907191: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:248] kernel version seems to match DSO: 535.183.1\n"
     ]
    }
   ],
   "source": [
    "model = load_model('../../models/eqn-detect-model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(img):\n",
    "    # Convert to grayscale\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Perform adaptive thresholding\n",
    "    binarized = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Invert binary image\n",
    "    inverted_binary_img = cv2.bitwise_not(binarized)\n",
    "    \n",
    "    # Expand dimensions to make it suitable for model input\n",
    "    expanded_img = np.expand_dims(inverted_binary_img, -1)\n",
    "    \n",
    "    return expanded_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOverlap(x_i, x_j):\n",
    "    if max(x_i) > min(x_j) and max(x_j) > min(x_i):  # Check for overlap\n",
    "        return min(max(x_i) - min(x_j), max(x_j) - min(x_i))  # Return overlap size\n",
    "    return 0  # No overlap\n",
    "\n",
    "def detect_contours(frame, min_width=30, min_height=30, canny_threshold1=100, canny_threshold2=150):\n",
    "    # Converter para escala de cinza\n",
    "    input_image_cpy = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Aplicar o detector de bordas de Canny\n",
    "    edges = cv2.Canny(input_image_cpy, canny_threshold1, canny_threshold2)\n",
    "    \n",
    "    # Encontrar contornos\n",
    "    contours_list, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    bounding_boxes = []\n",
    "    for i, c in enumerate(contours_list):\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        \n",
    "        # Filtrar contornos com base no tamanho mínimo\n",
    "        if w >= min_width and h >= min_height:\n",
    "            bounding_boxes.append([x, y, w, h, i])  # Adicionar índice do contorno\n",
    "    \n",
    "    filtered_boxes = []\n",
    "    for box in bounding_boxes:\n",
    "        x, y, w, h, idx = box\n",
    "        is_within_another = False\n",
    "        \n",
    "        # Verificar se este contorno está dentro de outro contorno maior\n",
    "        current_hierarchy = hierarchy[0][idx]\n",
    "        parent_idx = current_hierarchy[3]\n",
    "        \n",
    "        while parent_idx != -1:\n",
    "            px, py, pw, ph = cv2.boundingRect(contours_list[parent_idx])\n",
    "            if pw >= min_width and ph >= min_height:\n",
    "                is_within_another = True\n",
    "                break\n",
    "            parent_idx = hierarchy[0][parent_idx][3]\n",
    "        \n",
    "        if not is_within_another:\n",
    "            filtered_boxes.append([x, y, w, h])\n",
    "    \n",
    "    return filtered_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_pad(img, size, padColor=255):\n",
    "    h, w = img.shape[:2]\n",
    "    sh, sw = size\n",
    "\n",
    "    # interpolation method\n",
    "    if h > sh or w > sw: # shrinking image\n",
    "        interp = cv2.INTER_AREA\n",
    "    else: # stretching image\n",
    "        interp = cv2.INTER_CUBIC\n",
    "\n",
    "    # aspect ratio of image\n",
    "    aspect = w / h\n",
    "\n",
    "    # compute scaling and pad sizing\n",
    "    if aspect > 1: # horizontal image\n",
    "        new_w = sw\n",
    "        new_h = int(round(new_w / aspect))\n",
    "        pad_vert = (sh - new_h) / 2\n",
    "        pad_top, pad_bot = int(np.floor(pad_vert)), int(np.ceil(pad_vert))\n",
    "        pad_left, pad_right = 0, 0\n",
    "    elif aspect < 1: # vertical image\n",
    "        new_h = sh\n",
    "        new_w = int(round(new_h * aspect))\n",
    "        pad_horz = (sw - new_w) / 2\n",
    "        pad_left, pad_right = int(np.floor(pad_horz)), int(np.ceil(pad_horz))\n",
    "        pad_top, pad_bot = 0, 0\n",
    "    else: # square image\n",
    "        new_h, new_w = sh, sw\n",
    "        pad_left, pad_right, pad_top, pad_bot = 0, 0, 0, 0\n",
    "\n",
    "    # set pad color\n",
    "    if len(img.shape) == 3 and not isinstance(padColor, (list, tuple, np.ndarray)):\n",
    "        padColor = [padColor] * 3\n",
    "\n",
    "    # scale and pad\n",
    "    scaled_img = cv2.resize(img, (new_w, new_h), interpolation=interp)\n",
    "    scaled_img = cv2.copyMakeBorder(scaled_img, pad_top, pad_bot, pad_left, pad_right, borderType=cv2.BORDER_CONSTANT, value=padColor)\n",
    "\n",
    "    return scaled_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the IMAGE from webcam in real time, show the equation in the webcam in real time\n",
    "eqn_list = []\n",
    "def preprocess_webcam_image(img):\n",
    "    inverted_binary_img = binarize(img)\n",
    "    keep = detect_contours(img)\n",
    "    for (x, y, w, h) in sorted(keep, key = lambda x: x[0]):\n",
    "        img = resize_pad(inverted_binary_img[y:y+h, x:x+w], (45, 45), 0) # We must use the binarized image to predict\n",
    "        pred_class = class_names[np.argmax(model.predict(tf.expand_dims(tf.expand_dims(img, 0), -1)))]\n",
    "        \n",
    "        if pred_class == \"times\":\n",
    "            pred_class = \"*\"\n",
    "        eqn_list.append(pred_class)\n",
    "        # print(eqn_list)\n",
    "    eqn = \"\".join(eqn_list)\n",
    "    \n",
    "    return eqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_equation(equation):\n",
    "    # Trata casos de existência de igualdade sem valor\n",
    "    if \"=\" in equation:\n",
    "        # Dividir a equação em lado esquerdo e direito\n",
    "        left, right = equation.split(\"=\")\n",
    "        left = left.strip()\n",
    "        right = right.strip()\n",
    "        if not left and not right:\n",
    "            raise(\"Não tem equação\")\n",
    "        if not left:\n",
    "            equation = right\n",
    "        elif not right:\n",
    "            equation = left\n",
    "        else:\n",
    "            equation = equation\n",
    "\n",
    "    # Detectar o caso baseado no conteúdo da equação\n",
    "    if isinstance(equation, list):\n",
    "        left_expr = equation[0].lhs\n",
    "        right_expr = equation[0].rhs\n",
    "    else:\n",
    "        if \"=\" in str(equation):\n",
    "            left_expr = equation.lhs\n",
    "            right_expr = equation.rhs\n",
    "        else:\n",
    "            left_expr = equation\n",
    "            right_expr = sp.S.Zero\n",
    "\n",
    "    # Tentar converter as expressões para símbolos\n",
    "    try:\n",
    "        left_expr = sp.sympify(left_expr)\n",
    "        right_expr = sp.sympify(right_expr)\n",
    "    except sp.SympifyError:\n",
    "        return \"Equação inválida\"\n",
    "\n",
    "    # Caso 1: equação apenas numérica\n",
    "    if left_expr.is_number and right_expr.is_number:\n",
    "        result = left_expr - right_expr\n",
    "        return result.evalf()  # Usar evalf() para obter o valor numérico\n",
    "\n",
    "    # Caso 2 e 3: equações com variáveis\n",
    "    variables = list(left_expr.free_symbols | right_expr.free_symbols)\n",
    "\n",
    "    # Resolver a equação usando solve\n",
    "    solutions = sp.solve(left_expr - right_expr, variables)\n",
    "\n",
    "    # Melhorar a legibilidade das soluções\n",
    "    numeric_solutions = [sol.evalf() for sol in solutions]\n",
    "    \n",
    "    return numeric_solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao abrir a câmera.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@38.067] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video2): can't open camera by index\n",
      "[ERROR:0@38.183] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n"
     ]
    }
   ],
   "source": [
    "def most_frequent(List):\n",
    "    return max(set(List), key = List.count)\n",
    "\n",
    "cap = cv2.VideoCapture(2)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Erro ao abrir a câmera.\")\n",
    "else:\n",
    "    count = 0 \n",
    "    eqn_list = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "\n",
    "        eqn = preprocess_webcam_image(frame)\n",
    "        eqn_list.append(eqn)\n",
    "        # Process frame to detect contours\n",
    "        detected_boxes = detect_contours(frame)\n",
    "\n",
    "        for box in detected_boxes:\n",
    "            x, y, w, h = box\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Green rectangle\n",
    "\n",
    "\n",
    "        if count % 20 == 0:\n",
    "            print(eqn_list)\n",
    "            real_eqn = most_frequent(eqn_list)\n",
    "            print(real_eqn)\n",
    "            if real_eqn:\n",
    "                result = solve_equation(real_eqn)\n",
    "            else:\n",
    "                result = \"Nao foi encontrada uma equacao\"\n",
    "            eqn_list = []\n",
    "        \n",
    "        # Display the frame with detected contours\n",
    "        if result == \"Nao foi encontrada uma equacao\":\n",
    "            cv2.putText(frame, f\"{result}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "            cv2.putText(frame, f\"{real_eqn} = {result:.5}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        count += 1\n",
    "        cv2.imshow('Detected Contours', frame)\n",
    "    \n",
    "\n",
    "        # Exit the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
